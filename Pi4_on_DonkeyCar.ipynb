{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pi4_on_DonkeyCar.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Uwl-Ct1QZapS",
        "JopyWPttXqAa",
        "8IYt3nB5a-DH",
        "fXFZtafMdoKh",
        "v7lKyuc5juu3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edforpcc/mycar/blob/master/Pi4_on_DonkeyCar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0R2ggFajp8m"
      },
      "source": [
        "# 1- 存到你的 Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGXyqGncjp8b"
      },
      "source": [
        "- [CC-BY](http://creativecommons.org/licenses/by/3.0/tw/) [十百千實驗室](https://medium.com/十百千實驗室)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNJPVrXDXWBY"
      },
      "source": [
        "# 2- Colab Notebook 基本操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZCyuJ_E1Wrm"
      },
      "source": [
        "## 2-0 更新 runtime，換成 tensorflow-1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7epBDm8dwZgq"
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v_dH_csG2sh"
      },
      "source": [
        "## 2-1 測試是否支援GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qITFrlf9God4",
        "outputId": "3aa8eaf7-816a-406f-d626-276b1d5e689a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwl-Ct1QZapS"
      },
      "source": [
        "## 2-2 進、出、換 cell\n",
        "1. ENTER進cell\n",
        "2. ESC出cell\n",
        "3. ↑↓換cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JopyWPttXqAa"
      },
      "source": [
        "## 2-2 上增、下增、刪除、轉換 cell\n",
        "1. CMD/CTRL+m a (above的意思)\n",
        "2. CMD/CTRL+m b (below的意思)\n",
        "3. CMD/CTRL+m d (delete的意思)\n",
        "4. CMD/CTRL+m m/y (轉成text/code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IYt3nB5a-DH"
      },
      "source": [
        "## 2-3 在cell內\n",
        "1. ENTER換行編輯cell\n",
        "2. SHIFT+ENTER執行cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXFZtafMdoKh"
      },
      "source": [
        "## 2-4 上一步/下一步\n",
        "1. 在cell內：CMD/CTRL+z/y \n",
        "2. 在cell外：CMD/CTRL+SHIFT+z/y "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7lKyuc5juu3"
      },
      "source": [
        "## 2-5 Runtime\n",
        "1. restart 重開機的概念\n",
        "2. reset 重置、重灌的概念\n",
        "3. 換成GPU的，GPU的平行運算能大幅縮短神經網路的訓練時間"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CORTmaGdz7r"
      },
      "source": [
        "# 3- 在 Colab 操作 Linux 指令"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YahOeLaofN_x"
      },
      "source": [
        "1. 你的Google雲端硬碟裡的Colab Notebook是跑在1.5hr/12hr自動重置的Linux虛擬機上\n",
        "2. 資料科學、機器學習、深度學習(神經網路)、Google Cloud API相關的Python函式庫皆已安裝\n",
        "3. 現成的AI實驗開發環境，使用Python程式語言\n",
        "4. 前置一個驚嘆號，使用Linux指令操作虛擬機\n",
        "5. 用 && 解決無法停留在 cd 後的工作目錄的問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdQg-bwNT2da"
      },
      "source": [
        "# 4- 訓練（學）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGf8mEP4InQ6"
      },
      "source": [
        "## 4-1 安裝 Donkeycar 開發套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZQCTMl45KLJ",
        "outputId": "93946ba6-1213-4704-db3a-3b9cc0e25fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/autorope/donkeycar\n",
        "! cd donkeycar && git checkout master\n",
        "! cd donkeycar && git checkout 0812f83\n",
        "! cd donkeycar && time pip3 install -e ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'donkeycar'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 13814 (delta 1), reused 3 (delta 0), pack-reused 13801\u001b[K\n",
            "Receiving objects: 100% (13814/13814), 81.57 MiB | 42.66 MiB/s, done.\n",
            "Resolving deltas: 100% (8720/8720), done.\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Switched to a new branch 'master'\n",
            "Note: checking out '0812f83'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 0812f83 fix path to sim on mac\n",
            "Obtaining file:///content/donkeycar\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (7.0.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (0.6.2)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (2.10.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (0.2.3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (1.1.4)\n",
            "Requirement already satisfied: PrettyTable in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (1.0.1)\n",
            "Collecting paho-mqtt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/d3/6dcb8fd14746fcde6a556f932b5de8bea8fedcb85b3a092e0e986372c0e7/paho-mqtt-1.5.1.tar.gz (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.2) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->donkeycar==3.1.2) (1.15.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.2) (4.41.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.2) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.2) (2.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.2) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from PrettyTable->donkeycar==3.1.2) (0.2.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from PrettyTable->donkeycar==3.1.2) (50.3.2)\n",
            "Building wheels for collected packages: paho-mqtt\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.5.1-cp36-none-any.whl size=61544 sha256=8ee120588429e7086104e93a325c4a6f85d4e91c6c4281e01053549221d62b16\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/f5/78942b19b4d135605e58dfe85fba52253b14d636aabf76904b\n",
            "Successfully built paho-mqtt\n",
            "Installing collected packages: paho-mqtt, donkeycar\n",
            "  Running setup.py develop for donkeycar\n",
            "Successfully installed donkeycar paho-mqtt-1.5.1\n",
            "\n",
            "real\t0m5.048s\n",
            "user\t0m3.992s\n",
            "sys\t0m0.485s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts8Ml-l2IMpP"
      },
      "source": [
        "## 4-2 安裝搖桿程式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxskIwLvPIiu",
        "outputId": "79acc3d9-e261-4de8-f39e-b708e7616107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/raspberrypi-tw/donkeypart_ps3_controller\n",
        "! cd donkeypart_ps3_controller && python3 setup.py install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'donkeypart_ps3_controller'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 118 (delta 2), reused 6 (delta 2), pack-reused 112\u001b[K\n",
            "Receiving objects: 100% (118/118), 61.03 KiB | 5.55 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating donkeypart_ps3_controller.egg-info\n",
            "writing donkeypart_ps3_controller.egg-info/PKG-INFO\n",
            "writing dependency_links to donkeypart_ps3_controller.egg-info/dependency_links.txt\n",
            "writing top-level names to donkeypart_ps3_controller.egg-info/top_level.txt\n",
            "writing manifest file 'donkeypart_ps3_controller.egg-info/SOURCES.txt'\n",
            "writing manifest file 'donkeypart_ps3_controller.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/donkeypart_ps3_controller\n",
            "copying donkeypart_ps3_controller/part.py -> build/lib/donkeypart_ps3_controller\n",
            "copying donkeypart_ps3_controller/__init__.py -> build/lib/donkeypart_ps3_controller\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/donkeypart_ps3_controller\n",
            "copying build/lib/donkeypart_ps3_controller/part.py -> build/bdist.linux-x86_64/egg/donkeypart_ps3_controller\n",
            "copying build/lib/donkeypart_ps3_controller/__init__.py -> build/bdist.linux-x86_64/egg/donkeypart_ps3_controller\n",
            "byte-compiling build/bdist.linux-x86_64/egg/donkeypart_ps3_controller/part.py to part.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/donkeypart_ps3_controller/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying donkeypart_ps3_controller.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying donkeypart_ps3_controller.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying donkeypart_ps3_controller.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying donkeypart_ps3_controller.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/donkeypart_ps3_controller-0.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing donkeypart_ps3_controller-0.0-py3.6.egg\n",
            "Copying donkeypart_ps3_controller-0.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding donkeypart-ps3-controller 0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/donkeypart_ps3_controller-0.0-py3.6.egg\n",
            "Processing dependencies for donkeypart-ps3-controller==0.0\n",
            "Finished processing dependencies for donkeypart-ps3-controller==0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrTdaCR4FFzs"
      },
      "source": [
        "## 4-3-1 完整複製（git clone）從樹莓派上傳（git push）至 GitHub 的 Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWaMVOZJIWD7",
        "outputId": "193e99eb-af70-4dcd-b017-7e960892b87d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 從 github 拉下你的<ID> mycar<REPO> => 角括號要去掉\n",
        "! git clone https://github.com/edforpcc/mycar"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mycar'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 81034 (delta 0), reused 2 (delta 0), pack-reused 81030\u001b[K\n",
            "Receiving objects: 100% (81034/81034), 202.53 MiB | 39.63 MiB/s, done.\n",
            "Resolving deltas: 100% (40738/40738), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdZcIxiafC7u"
      },
      "source": [
        "# 複製 sample_manage.py 到 <REPO>\n",
        "! cp donkeypart_ps3_controller/sample_manage.py mycar"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmJ03Q97FlxL"
      },
      "source": [
        "## 4-3-2 下載差異（git pull）從樹莓派上傳（git push）至 GitHub 的 Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZt6MZLmteBb",
        "outputId": "c8e3f24f-2d3b-4557-ee9f-1789d1cd0697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 更新 Colab <REPO> 資料\n",
        "! cd mycar && rm -rf models\n",
        "! cd mycar && git pull"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVEb-VpfGPFw"
      },
      "source": [
        "## 4-4 訓練各種深度神經網路 aka 深度學習模型\n",
        "1. model 自行命名，但副檔名必須是.h5\n",
        "2. type 選項  \n",
        "https://github.com/autorope/donkeycar/blob/dev/donkeycar/templates/train.py#L13\n",
        "3. DonkeyCar已實作的各種模型的說明和比較  \n",
        "http://docs.donkeycar.com/parts/keras/\n",
        "4. batch = 一次訓練的樣本數  \n",
        "epoch = 完整訓練的回合數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTGjZ1ORIkIH",
        "outputId": "a1b538a9-3618-47b3-9bae-54ad29f85750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 進到 <REPO> 以後進行訓練，預設使用 linear\n",
        "! mkdir mycar/models\n",
        "! cd mycar && python sample_manage.py train --model models/lin_1.h5  # --tub data/tub資料夾名稱,data/tub資料夾名稱,..."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.2 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "myconfig myconfig.py\n",
            "loading personal config over-rides from myconfig.py\n",
            "\n",
            "config loaded\n",
            "2020-11-19 01:59:14.563215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "using default model type of linear\n",
            "\"get_model_by_type\" model Type is: linear\n",
            "2020-11-19 01:59:15.957550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-11-19 01:59:15.961861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:15.962422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-11-19 01:59:15.962464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-19 01:59:15.964255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-19 01:59:15.970942: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-19 01:59:15.971310: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-19 01:59:15.977133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-19 01:59:15.978005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-19 01:59:15.992198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-19 01:59:15.992308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:15.992865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:15.993380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-11-19 01:59:16.001400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-11-19 01:59:16.001581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19fd100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-19 01:59:16.001606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-11-19 01:59:16.093693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:16.094363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19fd2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-19 01:59:16.094396: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-11-19 01:59:16.094608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:16.095144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-11-19 01:59:16.095212: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-19 01:59:16.095268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-19 01:59:16.095289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-19 01:59:16.095311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-19 01:59:16.095329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-19 01:59:16.095347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-19 01:59:16.095366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-19 01:59:16.095438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:16.096017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:16.096515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-11-19 01:59:16.096571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-19 01:59:16.676888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-19 01:59:16.676954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-11-19 01:59:16.676966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-11-19 01:59:16.677201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:16.677777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 01:59:16.678299: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-11-19 01:59:16.678341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13758 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "training with model type <class 'donkeycar.parts.keras.KerasLinear'>\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_in (InputLayer)             [(None, 120, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 58, 78, 24)   1824        img_in[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 58, 78, 24)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 27, 37, 32)   19232       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 27, 37, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 12, 17, 64)   51264       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 12, 17, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 15, 64)   36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 10, 15, 64)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 13, 64)    36928       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 13, 64)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flattened (Flatten)             (None, 6656)         0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          665700      flattened[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 50)           5050        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 50)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs0 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs1 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 817,028\n",
            "Trainable params: 817,028\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "found 0 pickles writing json records and images in tub /content/mycar/data/tub_22_20-10-21\n",
            "/content/mycar/data/tub_22_20-10-21\n",
            "collating 4657 records ...\n",
            "train: 3725, val: 932\n",
            "total records: 4657\n",
            "steps_per_epoch 29\n",
            "WARNING:tensorflow:From /content/mycar/train.py:590: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "2020-11-19 01:59:18.104002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-19 01:59:19.603864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.4001 - n_outputs0_loss: 0.3441 - n_outputs1_loss: 0.0559\n",
            "Epoch 00001: val_loss improved from inf to 0.24430, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 0.4001 - n_outputs0_loss: 0.3441 - n_outputs1_loss: 0.0559 - val_loss: 0.2443 - val_n_outputs0_loss: 0.2373 - val_n_outputs1_loss: 0.0070\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.2257 - n_outputs0_loss: 0.2153 - n_outputs1_loss: 0.0104\n",
            "Epoch 00002: val_loss improved from 0.24430 to 0.19910, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 2s 54ms/step - loss: 0.2257 - n_outputs0_loss: 0.2153 - n_outputs1_loss: 0.0104 - val_loss: 0.1991 - val_n_outputs0_loss: 0.1972 - val_n_outputs1_loss: 0.0019\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1951 - n_outputs0_loss: 0.1864 - n_outputs1_loss: 0.0087\n",
            "Epoch 00003: val_loss improved from 0.19910 to 0.18335, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 1s 52ms/step - loss: 0.1951 - n_outputs0_loss: 0.1864 - n_outputs1_loss: 0.0087 - val_loss: 0.1833 - val_n_outputs0_loss: 0.1806 - val_n_outputs1_loss: 0.0028\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1724 - n_outputs0_loss: 0.1657 - n_outputs1_loss: 0.0067\n",
            "Epoch 00004: val_loss did not improve from 0.18335\n",
            "29/29 [==============================] - 1s 41ms/step - loss: 0.1724 - n_outputs0_loss: 0.1657 - n_outputs1_loss: 0.0067 - val_loss: 0.1956 - val_n_outputs0_loss: 0.1933 - val_n_outputs1_loss: 0.0023\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1740 - n_outputs0_loss: 0.1671 - n_outputs1_loss: 0.0068\n",
            "Epoch 00005: val_loss did not improve from 0.18335\n",
            "29/29 [==============================] - 1s 43ms/step - loss: 0.1740 - n_outputs0_loss: 0.1671 - n_outputs1_loss: 0.0068 - val_loss: 0.1848 - val_n_outputs0_loss: 0.1829 - val_n_outputs1_loss: 0.0019\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1658 - n_outputs0_loss: 0.1595 - n_outputs1_loss: 0.0063\n",
            "Epoch 00006: val_loss improved from 0.18335 to 0.17826, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 2s 53ms/step - loss: 0.1658 - n_outputs0_loss: 0.1595 - n_outputs1_loss: 0.0063 - val_loss: 0.1783 - val_n_outputs0_loss: 0.1723 - val_n_outputs1_loss: 0.0060\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1622 - n_outputs0_loss: 0.1564 - n_outputs1_loss: 0.0058\n",
            "Epoch 00007: val_loss did not improve from 0.17826\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.1622 - n_outputs0_loss: 0.1564 - n_outputs1_loss: 0.0058 - val_loss: 0.1841 - val_n_outputs0_loss: 0.1807 - val_n_outputs1_loss: 0.0034\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1628 - n_outputs0_loss: 0.1567 - n_outputs1_loss: 0.0060\n",
            "Epoch 00008: val_loss did not improve from 0.17826\n",
            "29/29 [==============================] - 1s 43ms/step - loss: 0.1628 - n_outputs0_loss: 0.1567 - n_outputs1_loss: 0.0060 - val_loss: 0.1791 - val_n_outputs0_loss: 0.1772 - val_n_outputs1_loss: 0.0019\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1566 - n_outputs0_loss: 0.1516 - n_outputs1_loss: 0.0050\n",
            "Epoch 00009: val_loss improved from 0.17826 to 0.17426, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 2s 52ms/step - loss: 0.1566 - n_outputs0_loss: 0.1516 - n_outputs1_loss: 0.0050 - val_loss: 0.1743 - val_n_outputs0_loss: 0.1738 - val_n_outputs1_loss: 4.3150e-04\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1564 - n_outputs0_loss: 0.1515 - n_outputs1_loss: 0.0049\n",
            "Epoch 00010: val_loss did not improve from 0.17426\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.1564 - n_outputs0_loss: 0.1515 - n_outputs1_loss: 0.0049 - val_loss: 0.1841 - val_n_outputs0_loss: 0.1794 - val_n_outputs1_loss: 0.0048\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1541 - n_outputs0_loss: 0.1482 - n_outputs1_loss: 0.0059\n",
            "Epoch 00011: val_loss improved from 0.17426 to 0.17192, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 2s 52ms/step - loss: 0.1541 - n_outputs0_loss: 0.1482 - n_outputs1_loss: 0.0059 - val_loss: 0.1719 - val_n_outputs0_loss: 0.1709 - val_n_outputs1_loss: 0.0011\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1473 - n_outputs0_loss: 0.1429 - n_outputs1_loss: 0.0043\n",
            "Epoch 00012: val_loss did not improve from 0.17192\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.1473 - n_outputs0_loss: 0.1429 - n_outputs1_loss: 0.0043 - val_loss: 0.1726 - val_n_outputs0_loss: 0.1715 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1408 - n_outputs0_loss: 0.1368 - n_outputs1_loss: 0.0040\n",
            "Epoch 00013: val_loss improved from 0.17192 to 0.15968, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 1s 51ms/step - loss: 0.1408 - n_outputs0_loss: 0.1368 - n_outputs1_loss: 0.0040 - val_loss: 0.1597 - val_n_outputs0_loss: 0.1578 - val_n_outputs1_loss: 0.0019\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1353 - n_outputs0_loss: 0.1317 - n_outputs1_loss: 0.0036\n",
            "Epoch 00014: val_loss improved from 0.15968 to 0.15025, saving model to models/lin_1.h5\n",
            "29/29 [==============================] - 2s 53ms/step - loss: 0.1353 - n_outputs0_loss: 0.1317 - n_outputs1_loss: 0.0036 - val_loss: 0.1503 - val_n_outputs0_loss: 0.1498 - val_n_outputs1_loss: 4.7593e-04\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1313 - n_outputs0_loss: 0.1279 - n_outputs1_loss: 0.0034\n",
            "Epoch 00015: val_loss did not improve from 0.15025\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.1313 - n_outputs0_loss: 0.1279 - n_outputs1_loss: 0.0034 - val_loss: 0.1671 - val_n_outputs0_loss: 0.1664 - val_n_outputs1_loss: 7.2881e-04\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1291 - n_outputs0_loss: 0.1259 - n_outputs1_loss: 0.0032\n",
            "Epoch 00016: val_loss did not improve from 0.15025\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.1291 - n_outputs0_loss: 0.1259 - n_outputs1_loss: 0.0032 - val_loss: 0.1617 - val_n_outputs0_loss: 0.1603 - val_n_outputs1_loss: 0.0013\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1206 - n_outputs0_loss: 0.1174 - n_outputs1_loss: 0.0032\n",
            "Epoch 00017: val_loss did not improve from 0.15025\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.1206 - n_outputs0_loss: 0.1174 - n_outputs1_loss: 0.0032 - val_loss: 0.1589 - val_n_outputs0_loss: 0.1582 - val_n_outputs1_loss: 6.4946e-04\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1136 - n_outputs0_loss: 0.1107 - n_outputs1_loss: 0.0029\n",
            "Epoch 00018: val_loss did not improve from 0.15025\n",
            "29/29 [==============================] - 1s 42ms/step - loss: 0.1136 - n_outputs0_loss: 0.1107 - n_outputs1_loss: 0.0029 - val_loss: 0.1582 - val_n_outputs0_loss: 0.1573 - val_n_outputs1_loss: 9.0824e-04\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.1115 - n_outputs0_loss: 0.1085 - n_outputs1_loss: 0.0030\n",
            "Epoch 00019: val_loss did not improve from 0.15025\n",
            "29/29 [==============================] - 1s 43ms/step - loss: 0.1115 - n_outputs0_loss: 0.1085 - n_outputs1_loss: 0.0030 - val_loss: 0.1673 - val_n_outputs0_loss: 0.1658 - val_n_outputs1_loss: 0.0015\n",
            "Epoch 00019: early stopping\n",
            "Training completed in 0:00:36.\n",
            "\n",
            "\n",
            "----------- Best Eval Loss :0.150252 ---------\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyxU7E2JFSVm"
      },
      "source": [
        "# 進到 <REPO> 以後進行訓練，這次使用 categorical\n",
        "! mkdir mycar/models\n",
        "! cd mycar && python sample_manage.py train --model models/cat_1.h5 --type categorical # --tub data/tub資料夾名稱,data/tub資料夾名稱,..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlXIsAe-177b"
      },
      "source": [
        "# 進到 <REPO> 以後進行訓練，這次使用 rnn\n",
        "! mkdir mycar/models\n",
        "! cd mycar && python sample_manage.py train --model models/rnn_1.h5 --type rnn # --tub data/tub資料夾名稱,data/tub資料夾名稱,..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUJ9v5x6IxQF"
      },
      "source": [
        "## 4-5 遷移學習（增加訓練、增加技能）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDvO4snm2b7x",
        "outputId": "80b00fb6-5c08-466c-9114-8604e3356f52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! cd mycar && python sample_manage.py train --transfer models/rnn_1.h5 --model models/rnn_2.h5 --type rnn"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.2 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "myconfig myconfig.py\n",
            "loading personal config over-rides from myconfig.py\n",
            "\n",
            "config loaded\n",
            "2020-11-19 02:08:35.362961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "sequence of images training\n",
            "\"get_model_by_type\" model Type is: rnn\n",
            "2020-11-19 02:08:36.723857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-11-19 02:08:36.728145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:36.728694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-11-19 02:08:36.728732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-19 02:08:36.730350: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-19 02:08:36.735500: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-19 02:08:36.735792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-19 02:08:36.737885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-19 02:08:36.738909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-19 02:08:36.742603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-19 02:08:36.742708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:36.743281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:36.743773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-11-19 02:08:36.748975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-11-19 02:08:36.749172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a72bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-19 02:08:36.749206: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-11-19 02:08:36.842616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:36.843265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a72d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-11-19 02:08:36.843295: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-11-19 02:08:36.843467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:36.843988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-11-19 02:08:36.844034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-19 02:08:36.844093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-19 02:08:36.844115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-11-19 02:08:36.844139: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-11-19 02:08:36.844157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-11-19 02:08:36.844175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-11-19 02:08:36.844193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-11-19 02:08:36.844259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:36.844802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:36.845305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-11-19 02:08:36.845362: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-11-19 02:08:37.444576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-11-19 02:08:37.444634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-11-19 02:08:37.444646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-11-19 02:08:37.444822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:37.445447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-11-19 02:08:37.445959: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-11-19 02:08:37.446000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13758 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 3, 58, 78, 24)     1824      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 3, 58, 78, 24)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 3, 27, 37, 32)     19232     \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 3, 27, 37, 32)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 3, 13, 18, 32)     9248      \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 3, 13, 18, 32)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 3, 11, 16, 32)     9248      \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 3, 11, 16, 32)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 3, 5, 8, 32)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 3, 1280)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 3, 100)            128100    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "LSTM_seq (LSTM)              (None, 3, 128)            117248    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 128)            0         \n",
            "_________________________________________________________________\n",
            "LSTM_fin (LSTM)              (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "model_outputs (Dense)        (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 441,924\n",
            "Trainable params: 441,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Tub: /content/mycar/data/tub_22_20-10-21 has 4657 records\n",
            "collating records\n",
            "collating sequences\n",
            "collated 4629 sequences of length 3\n",
            "train: 3704, validation: 925\n",
            "steps_per_epoch 28\n",
            "WARNING:tensorflow:From /content/mycar/train.py:590: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "2020-11-19 02:08:41.050760: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-11-19 02:08:41.564042: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.2079\n",
            "Epoch 00001: val_loss improved from inf to 0.20685, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 5s 194ms/step - loss: 0.2079 - val_loss: 0.2068\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.1472\n",
            "Epoch 00002: val_loss improved from 0.20685 to 0.11645, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 121ms/step - loss: 0.1472 - val_loss: 0.1165\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.1007\n",
            "Epoch 00003: val_loss improved from 0.11645 to 0.08770, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 121ms/step - loss: 0.1007 - val_loss: 0.0877\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0882\n",
            "Epoch 00004: val_loss improved from 0.08770 to 0.08513, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 120ms/step - loss: 0.0882 - val_loss: 0.0851\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0839\n",
            "Epoch 00005: val_loss did not improve from 0.08513\n",
            "28/28 [==============================] - 3s 114ms/step - loss: 0.0839 - val_loss: 0.0884\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0856\n",
            "Epoch 00006: val_loss improved from 0.08513 to 0.07894, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 121ms/step - loss: 0.0856 - val_loss: 0.0789\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0813\n",
            "Epoch 00007: val_loss improved from 0.07894 to 0.07627, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 119ms/step - loss: 0.0813 - val_loss: 0.0763\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0790\n",
            "Epoch 00008: val_loss did not improve from 0.07627\n",
            "28/28 [==============================] - 3s 110ms/step - loss: 0.0790 - val_loss: 0.0794\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0792\n",
            "Epoch 00009: val_loss did not improve from 0.07627\n",
            "28/28 [==============================] - 3s 111ms/step - loss: 0.0792 - val_loss: 0.0769\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0785\n",
            "Epoch 00010: val_loss did not improve from 0.07627\n",
            "28/28 [==============================] - 3s 110ms/step - loss: 0.0785 - val_loss: 0.0808\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0790\n",
            "Epoch 00011: val_loss did not improve from 0.07627\n",
            "28/28 [==============================] - 3s 113ms/step - loss: 0.0790 - val_loss: 0.0768\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0767\n",
            "Epoch 00012: val_loss improved from 0.07627 to 0.07529, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 119ms/step - loss: 0.0767 - val_loss: 0.0753\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0770\n",
            "Epoch 00013: val_loss improved from 0.07529 to 0.07435, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 121ms/step - loss: 0.0770 - val_loss: 0.0744\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0768\n",
            "Epoch 00014: val_loss did not improve from 0.07435\n",
            "28/28 [==============================] - 3s 113ms/step - loss: 0.0768 - val_loss: 0.0777\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0755\n",
            "Epoch 00015: val_loss did not improve from 0.07435\n",
            "28/28 [==============================] - 3s 112ms/step - loss: 0.0755 - val_loss: 0.0772\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0749\n",
            "Epoch 00016: val_loss did not improve from 0.07435\n",
            "28/28 [==============================] - 3s 112ms/step - loss: 0.0749 - val_loss: 0.0768\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0750\n",
            "Epoch 00017: val_loss improved from 0.07435 to 0.07154, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 121ms/step - loss: 0.0750 - val_loss: 0.0715\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0745\n",
            "Epoch 00018: val_loss did not improve from 0.07154\n",
            "28/28 [==============================] - 3s 109ms/step - loss: 0.0745 - val_loss: 0.0726\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0729\n",
            "Epoch 00019: val_loss did not improve from 0.07154\n",
            "28/28 [==============================] - 3s 113ms/step - loss: 0.0729 - val_loss: 0.0798\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0724\n",
            "Epoch 00020: val_loss did not improve from 0.07154\n",
            "28/28 [==============================] - 3s 116ms/step - loss: 0.0724 - val_loss: 0.0723\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0720\n",
            "Epoch 00021: val_loss improved from 0.07154 to 0.06784, saving model to models/rnn_2.h5\n",
            "28/28 [==============================] - 3s 116ms/step - loss: 0.0720 - val_loss: 0.0678\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0712\n",
            "Epoch 00022: val_loss did not improve from 0.06784\n",
            "28/28 [==============================] - 3s 113ms/step - loss: 0.0712 - val_loss: 0.0732\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0707\n",
            "Epoch 00023: val_loss did not improve from 0.06784\n",
            "28/28 [==============================] - 3s 112ms/step - loss: 0.0707 - val_loss: 0.0742\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0712\n",
            "Epoch 00024: val_loss did not improve from 0.06784\n",
            "28/28 [==============================] - 3s 111ms/step - loss: 0.0712 - val_loss: 0.0726\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0708\n",
            "Epoch 00025: val_loss did not improve from 0.06784\n",
            "28/28 [==============================] - 3s 113ms/step - loss: 0.0708 - val_loss: 0.0712\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.0701\n",
            "Epoch 00026: val_loss did not improve from 0.06784\n",
            "28/28 [==============================] - 3s 116ms/step - loss: 0.0701 - val_loss: 0.0724\n",
            "Epoch 00026: early stopping\n",
            "Training completed in 0:01:34.\n",
            "\n",
            "\n",
            "----------- Best Eval Loss :0.067836 ---------\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2sD9AvSEFzy"
      },
      "source": [
        "# 5- 推論（用）"
      ]
    }
  ]
}